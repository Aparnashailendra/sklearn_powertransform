{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Transformer 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What? \n",
    "\n",
    "### Powertransformer is part of sklearn preprocessing module\n",
    "\n",
    "\n",
    "### The individual transformers can be found inside the SciPy stats module\n",
    "\n",
    "- The key part of this technique is found right in the name **TRANSFORM** \n",
    "- Two data transformers are inside this module \n",
    "    - Box-Cox Transformation (will take in **ONLY** positive values) \n",
    "    - Yeo Johnson Transformation (can take in **BOTH** positive and negative values) \n",
    "    - What about 0? \n",
    "        - She ain't no hero here... \n",
    "    \n",
    "    \n",
    "![alt text](boxcox_beforeafter.png \"Title\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Math \n",
    "\n",
    "## Lambda can be between -5 and 5\n",
    "\n",
    "## The Confidence Interval is important! \n",
    "\n",
    "![alt text](math_boxcox.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/57/8a9889d49d0d77905af5a7524fb2b468d2ef5fc723684f51f5ca63efed0d/scikit_learn-0.21.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (10.5MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5MB 4.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /anaconda3/envs/codewars/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /anaconda3/envs/codewars/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.17.3)\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/42/155696f85f344c066e17af287359c9786b436b1bf86029bb3411283274f3/joblib-0.14.0-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 4.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/patrickcavins/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.0 scikit-learn-0.21.3 sklearn-0.0\n",
      "Requirement already satisfied: matplotlib in /anaconda3/envs/codewars/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /anaconda3/envs/codewars/lib/python3.7/site-packages (from matplotlib) (1.17.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda3/envs/codewars/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda3/envs/codewars/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda3/envs/codewars/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda3/envs/codewars/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/envs/codewars/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/envs/codewars/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3e27413fe412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPowerTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#Libraries needed for this demonstration\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy import stats\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Data, in this case AMES Housing Data. We are only working with one-column \n",
    "df = pd.read_csv('./train.csv')\n",
    "\n",
    "df['Garage Area'].head(10)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Quick EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Garage Area'].isnull().sum()\n",
    "\n",
    "# there is only one nan object \n",
    "df['Garage Area'] = df['Garage Area'].replace(np.nan, 0)\n",
    "\n",
    "# I am only doing this because the box cox says that there are negative values... which isn't true?\n",
    "\n",
    "# I **think** it is because  of the zero, and the difference in the transformation which that requires. Yea.. \n",
    "\n",
    "df['Garage Area'] = df['Garage Area'].replace(0, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What don't have any nulls? \n",
    "print (df['Garage Area'].isnull().sum())\n",
    "\n",
    "# We have a non-zero minimun? \n",
    "print (df['Garage Area'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "garage_area = np.asarray(df['Garage Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that this data is screwed, and does not represent a normal distribution \n",
    "sns.kdeplot(garage_area, shade=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values in the Box-Cox Transformation\n",
    "# xt = (x**lambda - 1) / lambda \n",
    "\n",
    "#define the set of lambda's that we want to search over ()\n",
    "lmbda = np.linspace(start = .5, stop = 1.0, num =4) \n",
    "\n",
    "xt = []\n",
    "lambda_list = []\n",
    "for i in lmbda: \n",
    "    #x = the input data \n",
    "    x = garage_area \n",
    "    #box-cox transformation \n",
    "    transform = (x**i - 1) / i\n",
    "    #appending the list \n",
    "    xt.append(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('These are the tranformed values, Box-Cox Transformation for a given Lambda')\n",
    "print ('--'*50)\n",
    "print (xt[1]) # we can grab the individual values \n",
    "print ('--'*50)\n",
    "print ('These are the lambdas which we used in this transformation')\n",
    "print (lmbda) # this is the list of lambda's we generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(garage_area, shade=True, label=\"Raw\")\n",
    "sns.kdeplot(xt[0], shade=True, label= f\"BC_Tranform(Lambda Value: {round(lmbda[0],3)}\")\n",
    "sns.kdeplot(xt[1], shade=True, label= f\"BC_Tranform(Lambda Value: {round(lmbda[1],3)}\")\n",
    "sns.kdeplot(xt[2], shade=True, label= f\"BC_Tranform(Lambda Value: {round(lmbda[2],3)}\")\n",
    "sns.kdeplot(xt[3], shade=True, label= f\"BC_Tranform(Lambda Value: {round(lmbda[3],3)}\")\n",
    "\n",
    "# control x and y limits\n",
    "plt.ylim(0, 0.06)\n",
    "plt.xlim(0, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The trick of Box-Cox transformation is to find lambda value, \n",
    "# however in practice this is quite affordable. The following function returns \n",
    "# the transformed variable, lambda value, confidence interval for lambda according to certain alpha level.\n",
    "\n",
    "# garage_area_xt: transformed variable.\n",
    "# maxlog: lambda\n",
    "# interval: confidence interval\n",
    "\n",
    "# http://dataunderthehood.com/2018/01/15/box-cox-transformation-with-python/\n",
    "    \n",
    "garage_area_xt, maxlog, interval = stats.boxcox(garage_area, alpha=0.95)\n",
    "\n",
    "print (maxlog)\n",
    "print (interval)\n",
    "print (garage_area_xt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes in the KDE... \n",
    "sns.kdeplot(garage_area, shade=True, label=\"Raw\")\n",
    "sns.kdeplot(garage_area_xt, shade=True, label=\"Transformed\")\n",
    "plt.title('Comparing the Raw Input to the Transformed Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Z-Score (garage area)\n",
    "\n",
    "garage_area_std = np.std(garage_area)\n",
    "\n",
    "print (garage_area_std)\n",
    "\n",
    "garage_area_Z = ((garage_area -garage_area.mean()) / (garage_area_std)) \n",
    "\n",
    "# plt.hist(garage_area_Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Z-Score (garage area_xt)\n",
    "\n",
    "garage_area_xt_std = np.std(garage_area_xt)\n",
    "\n",
    "print (garage_area_xt_std)\n",
    "\n",
    "garage_area_xt_Z = ((garage_area_xt - garage_area_xt.mean()) / (garage_area_xt_std))\n",
    "\n",
    "# plt.hist(garage_area_xt_Z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes in the KDE!  \n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "sns.set_context('poster')\n",
    "sns.kdeplot(garage_area_Z, shade=True, color='navy', label=\"Raw (normalizaied)\")\n",
    "sns.kdeplot(garage_area_xt_Z, shade=True, color='gold', label=\"Transformed (normalized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the sklearn Modele "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use two features...\n",
    "\n",
    "print (df['Lot Area'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.kdeplot(df['Lot Area'], shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features \n",
    "X = df[['Garage Area', 'Lot Area']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate PowerTransformer \n",
    "\n",
    "\n",
    "### Parameters \n",
    "\n",
    "**method** : str, (default=’yeo-johnson’)\n",
    "\n",
    "**standardize** : boolean, default=True\n",
    "Set to True to apply zero-mean, unit-variance normalization to the transformed output.\n",
    "\n",
    "### Attributes\n",
    "\n",
    "**lambdas_**: array of float, shape (n_features,)\n",
    "The parameters of the power transformation for the selected features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='box-cox', standardize=True,) \n",
    "\n",
    "#Fit the data to the powertransformer\n",
    "skl_boxcox = pt.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are the lambdas \n",
    "skl_boxcox.lambdas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform \n",
    "skl_boxcox = pt.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skl_boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_area = np.asarray(df['Lot Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,8))\n",
    "sns.set_context('poster')\n",
    "sns.kdeplot(garage_area, shade=True, color='navy', label=\"Garage Area\")\n",
    "sns.kdeplot(lot_area, shade=True, color='gold', label=\"Lot Area\")\n",
    "\n",
    "# control x and y limits\n",
    "# plt.ylim(0, 0.06)\n",
    "# plt.xlim(0, 20_000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(skl_boxcox, bins=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Tidbits:\n",
    "\n",
    "\"Box-cox transformation is a statistical technique used to remove heteroscedasticity of a variable and also make it look like more normally distributed, which represents a big deal for statisticians and economists regarding normality and homoscedasticity assumptions for linear models.\"\n",
    "\n",
    "http://dataunderthehood.com/2018/01/15/box-cox-transformation-with-python/\n",
    "\n",
    "\n",
    "\n",
    "\"For example, the data may have a skew, meaning that the bell in the bell shape may be pushed one way or another.\"\n",
    "\n",
    "https://machinelearningmastery.com/how-to-transform-data-to-fit-the-normal-distribution/\n",
    "\n",
    "\n",
    "\n",
    "\"But, generally the answer is that for most meaningful analysis, you need the same 𝜆 value for all datasets. The reason is that the Box-Cox transformation **not only changes the scale of the data, it also changes the unit of measurement**. \"\n",
    "\n",
    "https://stats.stackexchange.com/questions/243975/skewness-transformation-for-one-but-not-the-other-variable/243984#243984\n",
    "\n",
    "https://stats.stackexchange.com/questions/243975/skewness-transformation-for-one-but-not-the-other-variable/243984#243984"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References: \n",
    "\n",
    "http://www.kmdatascience.com/2017/07/box-cox-transformations-in-python.html\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
